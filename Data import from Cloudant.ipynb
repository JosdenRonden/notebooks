{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "This notebook is intended for Python 2 with Spark 2.1. It uses SparkSession to load a CSV file stored in Bluemix object storage into a dataframe, filters that data, then writes the filtered data to a previoulsy created Cloudant database. This example notebook loads a CSV file containing Child Care providers in Massachusetts downloaded from https://data.mass.gov/Education/Program-list-for-Child-Care-Search-1-15-2015/cb6m-ccic\n\nThis first cell simply verifies the version of Spark you are using.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "spark.version"
        }, 
        {
            "source": "Cell 2: Replace the contents of the first cell by following these steps:\n1. Displaying the Files slide out panel.\n2. Select the Insert to code menu for your file, and select Insert Credentials.\n3. Replace the name of the inserted array with credentials_621 as referenced in the rest of the code. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "Cell 3: The following cell imports SparkSession from pyspark.sql. SparkSession is the entry point to programming Spark with the Dataset and DataFrame API.\nNext, the code defines a variable to set the credentials for authentication for the Bluemix Object Storage.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "Cell 4: The following cell reads the CSV file into a data frame, infers the schema, and then displays the first two entries.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "massdata = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .option('timestampFormat', 'MM/dd/yyyy')\\\n  .option('inferSchema', 'true')\\\n  .load('swift://' + credentials_621['container'] + '.' + name + '/' + credentials_621['filename'])\nmassdata.take(2)"
        }, 
        {
            "source": "Cell 5: The following cell prints the schema and a record count of the data frame contents.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "massdata.printSchema()\nmassdata.count()"
        }, 
        {
            "source": "Cell 6: The following cell displays the first 30 values in the Session1Name field. Notice that there are null values.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "massdata.select(\"Session1Name\").show(30)"
        }, 
        {
            "source": "Cell 7: The following cell filters the data to just those facilities that have a specified Session1Name. Then it displays the first two entries and a count of the filtered data.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sessiondata = massdata.filter(massdata.Session1Name.isNotNull())\nsessiondata.show(2)\nsessiondata.count()"
        }, 
        {
            "source": "Cell 8: The following cell displays the first 30 values in the Session1Name field. Notice that there are NO null values.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sessiondata.select(\"Session1Name\").show(30)"
        }, 
        {
            "source": "Cell 9: The following cell writes the contents of the sessiondata data frame to a Cloudant database called child_care. Note: The Cloudant database MUST already exist.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sessiondata.write.format(\"com.cloudant.spark\") \\\n  .option(\"cloudant.host\",\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx-bluemix.cloudant.com\") \\\n  .option(\"cloudant.username\",\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx-bluemix\") \\\n  .option(\"cloudant.password\",\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\") \\\n  .save(\"child_care\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}